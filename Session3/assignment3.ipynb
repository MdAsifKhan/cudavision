{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task we implement a simple single hidden layer neural networks with logistic regression classifier on CIFAR10 dataset. Our implementation consists of 2 main class:\n",
    "\n",
    "    MLP\n",
    "\n",
    "    Contains implementation of multilayer perceptron. NUmber of hidden layers specified by user. \n",
    "\n",
    "    ModelEvaluator\n",
    "\n",
    "    Class consisting of basic functionalities for training, testing and visualizing loss. \n",
    "    Additionally, implements Hinge Loss and Softmax loss without torch.nn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "import numpy as np\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, drop_p, n_out, act):\n",
    "        super(MLP, self).__init__()\n",
    "        '''\n",
    "        n_in: Number of Inputs\n",
    "        n_hidden: List with units in hidden layers\n",
    "        n_out: Number of Output Units\n",
    "        '''\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.n_hidden = n_hidden\n",
    "        self.p = drop_p\n",
    "        self.input_layer = nn.Linear(self.n_in, self.n_hidden[0])\n",
    "        if act =='relu':\n",
    "            self.nonlin = nn.ReLU()\n",
    "        elif act =='tanh':\n",
    "            self.nonlin = nn.Tanh()\n",
    "        elif act=='sigmoid':\n",
    "            self.nonlin = nn.Sigmoid()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(self.n_hidden)-1):\n",
    "            self.hidden.append(nn.Linear(self.n_hidden[i], self.n_hidden[i+1]))\n",
    "            self.hidden.append(self.nonlin) \n",
    "            self.hidden.append(nn.Dropout(p = self.p))\n",
    "        self.final_fc = nn.Linear(self.n_hidden[-1], self.n_out)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        forward pass\n",
    "        '''\n",
    "        X = self.nonlin(self.input_layer(X))\n",
    "        for layer in self.hidden:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic functionalities for evaluating model alongwith implementation of hinge and softmax loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, epochs, lr, loss_type='softmax', l2=0.0, use_gpu=False, optim='adam'):\n",
    "        '''\n",
    "        model: instance of pytorch model class\n",
    "        epochs: number of training epochs\n",
    "        lr: learning rate\n",
    "        use_gpu: to use gpu\n",
    "        optim: optimizer used for training, SGD or adam\n",
    "        '''\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "        self.loss_type = loss_type\n",
    "        self.l2 = l2\n",
    "        self.use_gpu = use_gpu\n",
    "        self.train_loss = []\n",
    "        self.test_loss = []\n",
    "\n",
    "        if self.use_gpu:\n",
    "            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            if self.device == 'cuda:0':\n",
    "                if torch.cuda.device_count()>1:\n",
    "                    self.model = nn.DataParallel(model)\n",
    "                self.model.to(device)\n",
    "\n",
    "        if optim=='adam':\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        elif optim=='sgd':\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr = lr, momentum=0.9)\n",
    "        elif optim=='adadelta':\n",
    "            self.optimizer = torch.optim.Adadelta(self.model.parameters(), lr = lr, eps=1e-6, weight_decay=0)\n",
    "        elif optim=='adagrad':\n",
    "            self.optimizer = torch.optim.Adagrad(self.model.parameters(), lr = lr, lr_decay=1e-6, weight_decay=0)\n",
    "        elif optim=='rmsprop':\n",
    "            self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr = lr, alpha=0.995, eps=1e-7, weight_decay=0)\n",
    "        else:\n",
    "            ValueError('Optimizer Not Supported')\n",
    "\n",
    "    def softmax_loss(self, scores, y_label):\n",
    "        '''\n",
    "        softmax loss without torch.nn\n",
    "        '''\n",
    "        exp_scores = torch.exp(scores - torch.max(scores, dim=1)[0].view(-1,1))\n",
    "        sum_exp_scores = exp_scores.sum(dim=1).view(-1,1)\n",
    "        softmax_prob = exp_scores/sum_exp_scores\n",
    "        loss = -torch.log(softmax_prob[np.arange(len(scores)), y_label])\n",
    "        loss = loss.sum()\n",
    "        return loss\n",
    "\n",
    "    def hinge_loss(self, scores, y_label):\n",
    "        '''\n",
    "        hinge loss for multiclass without torch.nn\n",
    "        '''\n",
    "        hinge_loss = torch.clamp(scores - scores[np.arange(len(scores)),y_label].view(-1,1) + 1, min=0)\n",
    "        hinge_loss[np.arange(len(scores)),y_label] = 0\n",
    "        hinge_loss = hinge_loss.sum()\n",
    "\n",
    "        return hinge_loss\n",
    "\n",
    "    def l2_regularization(self, loss, lam):\n",
    "        l2 = 0\n",
    "        for W in self.model.parameters():\n",
    "            l2 += W.norm(2)\n",
    "        loss = model.loss() + 0.5*lam*l2\n",
    "        return loss\t\n",
    "\n",
    "\n",
    "    def train(self, epoch, trainloader, print_every=100):\n",
    "        '''\n",
    "        method for training\n",
    "        '''\n",
    "        loss_batch = 0\n",
    "        for b_idx, (train_data, train_labels) in enumerate(trainloader):\n",
    "            if self.use_gpu and self.device == 'cuda:0':\n",
    "                train_data, train_labels = train_data.to(self.device), train_labels.to(self.device)\n",
    "            train_data = train_data.reshape(-1, 32*32*3)\n",
    "\n",
    "            # Scale Images\n",
    "            train_data = train_data / 255\n",
    "\n",
    "            # Forward Pass \n",
    "            train_preds = self.model.forward(train_data)\n",
    "\n",
    "            if self.loss_type=='softmax':\n",
    "                loss = self.softmax_loss(train_preds, train_labels)\n",
    "            elif self.loss_type =='hinge':\n",
    "                loss = self.hinge_loss(train_preds, train_labels)\n",
    "            else:\n",
    "                ValueError('Loss Not Supported')\n",
    "            if self.l2:\n",
    "                loss = l2_regularization(loss, lam)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if b_idx%print_every == 0:\n",
    "                print('Train Epoch: {0} [{1}/{2} ({3:.0f}%)]\\t Loss {4:.6f}'.\n",
    "                    format(epoch, b_idx*len(train_data), len(trainloader.dataset), \n",
    "                        100.*b_idx/len(trainloader), loss))\n",
    "\n",
    "            loss_batch += loss\n",
    "        loss_batch /= len(trainloader)\n",
    "        self.train_loss.append(loss_batch)    \n",
    "\n",
    "    def validation(self, valloader):\n",
    "        '''\n",
    "        method for testing\n",
    "        '''\n",
    "        correct_, total_ = 0, 0\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for val_data, val_labels in valloader:\n",
    "                if self.use_gpu and self.device == 'cuda:0':\n",
    "                    val_data, val_labels = test_data.to(self.device), val_labels.to(self.device)\n",
    "                val_data = val_data.reshape(-1, 32*32*3)\n",
    "                val_data = val_data / 255\n",
    "                val_preds = self.model.forward(val_data)\n",
    "\n",
    "                if self.loss_type=='softmax':\n",
    "                    loss += self.softmax_loss(val_preds, val_labels)\n",
    "                elif self.loss_type =='hinge':\n",
    "                    loss += self.hinge_loss(val_preds, val_labels)\n",
    "                else:\n",
    "                    ValueError('Loss Not Supported')\n",
    "\n",
    "                _, val_pred_labels = torch.max(val_preds.data, 1)\n",
    "                total_ += val_labels.size(0)\n",
    "                correct_ += (val_pred_labels.cpu() == val_labels.cpu()).sum()\n",
    "\n",
    "            loss /= len(valloader)\n",
    "            self.val_loss.append(loss)\n",
    "            accuracy_val = (100.0*correct_/total_)\n",
    "            print('Validation Loss {1:.2f} Accuracy on validation set {2:.2f}'.format(loss, accuracy_val))\n",
    "            return accuracy_val\n",
    "\n",
    "    def test(self, testloader):\n",
    "        '''\n",
    "        method for testing\n",
    "        '''\n",
    "        correct_, total_ = 0, 0\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for test_data, test_labels in testloader:\n",
    "                if self.use_gpu and self.device == 'cuda:0':\n",
    "                    test_data, test_labels = test_data.to(self.device), test_labels.to(self.device)\n",
    "                test_data = test_data.reshape(-1, 32*32*3)\n",
    "                test_data = test_data / 255\n",
    "                test_preds = self.model.forward(test_data)\n",
    "\n",
    "                if self.loss_type=='softmax':\n",
    "                    loss += self.softmax_loss(test_preds, test_labels)\n",
    "                elif self.loss_type =='hinge':\n",
    "                    loss += self.hinge_loss(test_preds, test_labels)\n",
    "                else:\n",
    "                    ValueError('Loss Not Supported')\n",
    "\n",
    "                _, test_pred_labels = torch.max(test_preds.data, 1)\n",
    "                total_ += test_labels.size(0)\n",
    "                correct_ += (test_pred_labels.cpu() == test_labels.cpu()).sum()\n",
    "\n",
    "            loss /= len(testloader)\n",
    "            self.test_loss.append(loss)\n",
    "            accuracy_test = (100*correct_/total_)\n",
    "            print('Accuracy of model on test set {0:.2f}'.format(accuracy_test))\n",
    "            return accuracy_test\n",
    "\n",
    "    def evaluator(self, trainloader, testloader, print_every=1000, validation=False):\n",
    "        for epoch in range(self.epochs):\n",
    "            self.train(epoch, trainloader, print_every=print_every)\n",
    "            if validation:\n",
    "                acc_ = self.validation(testloader)\n",
    "            else:\n",
    "                acc_ = self.test(testloader)\n",
    "        return acc_\n",
    "    def plot_loss(self, validation=False):\n",
    "        '''\n",
    "        to visualize loss\n",
    "        '''\n",
    "        plt.plot(range(len(self.train_loss)), self.train_loss, label='Training Loss')\n",
    "        if validation:\n",
    "            plt.plot(range(len(self.val_loss)), self.val_loss, label='Validation Loss')\n",
    "        else:\n",
    "            plt.plot(range(len(self.test_loss)), self.test_loss, label='Testing Loss')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Parameters\n",
    "n_in = np.prod(trainset[0][0].numpy().shape)\n",
    "n_out = len(classes)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 0.001\n",
    "n_hidden = 512\n",
    "epochs = 30\n",
    "# Data Loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\t Loss 485.452820\n",
      "Train Epoch: 0 [10000/50000 (20%)]\t Loss 373.308441\n",
      "Train Epoch: 0 [20000/50000 (40%)]\t Loss 385.771271\n",
      "Train Epoch: 0 [30000/50000 (60%)]\t Loss 357.116730\n",
      "Train Epoch: 0 [40000/50000 (80%)]\t Loss 348.463440\n",
      "Accuracy of model on test set 18.00\n",
      "Train Epoch: 1 [0/50000 (0%)]\t Loss 369.592621\n",
      "Train Epoch: 1 [10000/50000 (20%)]\t Loss 357.686401\n",
      "Train Epoch: 1 [20000/50000 (40%)]\t Loss 340.391846\n",
      "Train Epoch: 1 [30000/50000 (60%)]\t Loss 343.185516\n",
      "Train Epoch: 1 [40000/50000 (80%)]\t Loss 318.241882\n",
      "Accuracy of model on test set 24.00\n",
      "Train Epoch: 2 [0/50000 (0%)]\t Loss 368.164307\n",
      "Train Epoch: 2 [10000/50000 (20%)]\t Loss 325.187164\n",
      "Train Epoch: 2 [20000/50000 (40%)]\t Loss 345.665985\n",
      "Train Epoch: 2 [30000/50000 (60%)]\t Loss 336.853424\n",
      "Train Epoch: 2 [40000/50000 (80%)]\t Loss 358.013458\n",
      "Accuracy of model on test set 26.00\n",
      "Train Epoch: 3 [0/50000 (0%)]\t Loss 336.330780\n",
      "Train Epoch: 3 [10000/50000 (20%)]\t Loss 355.842712\n",
      "Train Epoch: 3 [20000/50000 (40%)]\t Loss 363.448029\n",
      "Train Epoch: 3 [30000/50000 (60%)]\t Loss 363.135742\n",
      "Train Epoch: 3 [40000/50000 (80%)]\t Loss 356.298706\n",
      "Accuracy of model on test set 27.00\n",
      "Train Epoch: 4 [0/50000 (0%)]\t Loss 353.267487\n",
      "Train Epoch: 4 [10000/50000 (20%)]\t Loss 371.237549\n",
      "Train Epoch: 4 [20000/50000 (40%)]\t Loss 350.023438\n",
      "Train Epoch: 4 [30000/50000 (60%)]\t Loss 355.257751\n",
      "Train Epoch: 4 [40000/50000 (80%)]\t Loss 345.891571\n",
      "Accuracy of model on test set 29.00\n",
      "Train Epoch: 5 [0/50000 (0%)]\t Loss 379.632568\n",
      "Train Epoch: 5 [10000/50000 (20%)]\t Loss 354.626221\n",
      "Train Epoch: 5 [20000/50000 (40%)]\t Loss 330.935242\n",
      "Train Epoch: 5 [30000/50000 (60%)]\t Loss 367.423767\n",
      "Train Epoch: 5 [40000/50000 (80%)]\t Loss 354.067108\n",
      "Accuracy of model on test set 29.00\n",
      "Train Epoch: 6 [0/50000 (0%)]\t Loss 335.256104\n",
      "Train Epoch: 6 [10000/50000 (20%)]\t Loss 355.081848\n",
      "Train Epoch: 6 [20000/50000 (40%)]\t Loss 357.648041\n",
      "Train Epoch: 6 [30000/50000 (60%)]\t Loss 354.466370\n",
      "Train Epoch: 6 [40000/50000 (80%)]\t Loss 326.460144\n",
      "Accuracy of model on test set 30.00\n",
      "Train Epoch: 7 [0/50000 (0%)]\t Loss 360.969788\n",
      "Train Epoch: 7 [10000/50000 (20%)]\t Loss 331.518402\n",
      "Train Epoch: 7 [20000/50000 (40%)]\t Loss 363.275421\n",
      "Train Epoch: 7 [30000/50000 (60%)]\t Loss 335.436890\n",
      "Train Epoch: 7 [40000/50000 (80%)]\t Loss 311.499451\n",
      "Accuracy of model on test set 30.00\n",
      "Train Epoch: 8 [0/50000 (0%)]\t Loss 351.535156\n",
      "Train Epoch: 8 [10000/50000 (20%)]\t Loss 354.075104\n",
      "Train Epoch: 8 [20000/50000 (40%)]\t Loss 310.099762\n",
      "Train Epoch: 8 [30000/50000 (60%)]\t Loss 332.148621\n",
      "Train Epoch: 8 [40000/50000 (80%)]\t Loss 376.332306\n",
      "Accuracy of model on test set 32.00\n",
      "Train Epoch: 9 [0/50000 (0%)]\t Loss 325.633942\n",
      "Train Epoch: 9 [10000/50000 (20%)]\t Loss 337.570190\n",
      "Train Epoch: 9 [20000/50000 (40%)]\t Loss 346.703125\n",
      "Train Epoch: 9 [30000/50000 (60%)]\t Loss 349.311371\n",
      "Train Epoch: 9 [40000/50000 (80%)]\t Loss 355.990906\n",
      "Accuracy of model on test set 32.00\n",
      "Train Epoch: 10 [0/50000 (0%)]\t Loss 317.647888\n",
      "Train Epoch: 10 [10000/50000 (20%)]\t Loss 337.635895\n",
      "Train Epoch: 10 [20000/50000 (40%)]\t Loss 345.952606\n",
      "Train Epoch: 10 [30000/50000 (60%)]\t Loss 355.512512\n",
      "Train Epoch: 10 [40000/50000 (80%)]\t Loss 333.972870\n",
      "Accuracy of model on test set 31.00\n",
      "Train Epoch: 11 [0/50000 (0%)]\t Loss 293.597717\n",
      "Train Epoch: 11 [10000/50000 (20%)]\t Loss 361.761047\n",
      "Train Epoch: 11 [20000/50000 (40%)]\t Loss 334.003387\n",
      "Train Epoch: 11 [30000/50000 (60%)]\t Loss 341.576233\n",
      "Train Epoch: 11 [40000/50000 (80%)]\t Loss 297.416870\n",
      "Accuracy of model on test set 31.00\n",
      "Train Epoch: 12 [0/50000 (0%)]\t Loss 339.586639\n",
      "Train Epoch: 12 [10000/50000 (20%)]\t Loss 343.372131\n",
      "Train Epoch: 12 [20000/50000 (40%)]\t Loss 317.742340\n",
      "Train Epoch: 12 [30000/50000 (60%)]\t Loss 310.053986\n",
      "Train Epoch: 12 [40000/50000 (80%)]\t Loss 346.488495\n",
      "Accuracy of model on test set 32.00\n",
      "Train Epoch: 13 [0/50000 (0%)]\t Loss 289.256104\n",
      "Train Epoch: 13 [10000/50000 (20%)]\t Loss 303.158600\n",
      "Train Epoch: 13 [20000/50000 (40%)]\t Loss 312.727509\n",
      "Train Epoch: 13 [30000/50000 (60%)]\t Loss 341.144928\n",
      "Train Epoch: 13 [40000/50000 (80%)]\t Loss 324.282928\n",
      "Accuracy of model on test set 33.00\n",
      "Train Epoch: 14 [0/50000 (0%)]\t Loss 293.654419\n",
      "Train Epoch: 14 [10000/50000 (20%)]\t Loss 320.792114\n",
      "Train Epoch: 14 [20000/50000 (40%)]\t Loss 320.238922\n",
      "Train Epoch: 14 [30000/50000 (60%)]\t Loss 298.623016\n",
      "Train Epoch: 14 [40000/50000 (80%)]\t Loss 326.686890\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 15 [0/50000 (0%)]\t Loss 299.210571\n",
      "Train Epoch: 15 [10000/50000 (20%)]\t Loss 317.220001\n",
      "Train Epoch: 15 [20000/50000 (40%)]\t Loss 340.712433\n",
      "Train Epoch: 15 [30000/50000 (60%)]\t Loss 335.973450\n",
      "Train Epoch: 15 [40000/50000 (80%)]\t Loss 305.925385\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 16 [0/50000 (0%)]\t Loss 322.293121\n",
      "Train Epoch: 16 [10000/50000 (20%)]\t Loss 309.669403\n",
      "Train Epoch: 16 [20000/50000 (40%)]\t Loss 344.968781\n",
      "Train Epoch: 16 [30000/50000 (60%)]\t Loss 362.797272\n",
      "Train Epoch: 16 [40000/50000 (80%)]\t Loss 347.598572\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 17 [0/50000 (0%)]\t Loss 360.703583\n",
      "Train Epoch: 17 [10000/50000 (20%)]\t Loss 300.837891\n",
      "Train Epoch: 17 [20000/50000 (40%)]\t Loss 391.391998\n",
      "Train Epoch: 17 [30000/50000 (60%)]\t Loss 360.681000\n",
      "Train Epoch: 17 [40000/50000 (80%)]\t Loss 326.376892\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 18 [0/50000 (0%)]\t Loss 319.638824\n",
      "Train Epoch: 18 [10000/50000 (20%)]\t Loss 316.476685\n",
      "Train Epoch: 18 [20000/50000 (40%)]\t Loss 373.590942\n",
      "Train Epoch: 18 [30000/50000 (60%)]\t Loss 324.984650\n",
      "Train Epoch: 18 [40000/50000 (80%)]\t Loss 365.628906\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 19 [0/50000 (0%)]\t Loss 338.444092\n",
      "Train Epoch: 19 [10000/50000 (20%)]\t Loss 317.087524\n",
      "Train Epoch: 19 [20000/50000 (40%)]\t Loss 303.180206\n",
      "Train Epoch: 19 [30000/50000 (60%)]\t Loss 328.127106\n",
      "Train Epoch: 19 [40000/50000 (80%)]\t Loss 355.151367\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 20 [0/50000 (0%)]\t Loss 357.218262\n",
      "Train Epoch: 20 [10000/50000 (20%)]\t Loss 335.367096\n",
      "Train Epoch: 20 [20000/50000 (40%)]\t Loss 317.575043\n",
      "Train Epoch: 20 [30000/50000 (60%)]\t Loss 288.980652\n",
      "Train Epoch: 20 [40000/50000 (80%)]\t Loss 312.081146\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 21 [0/50000 (0%)]\t Loss 333.356140\n",
      "Train Epoch: 21 [10000/50000 (20%)]\t Loss 330.488220\n",
      "Train Epoch: 21 [20000/50000 (40%)]\t Loss 336.850006\n",
      "Train Epoch: 21 [30000/50000 (60%)]\t Loss 333.948608\n",
      "Train Epoch: 21 [40000/50000 (80%)]\t Loss 326.748016\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 22 [0/50000 (0%)]\t Loss 260.263062\n",
      "Train Epoch: 22 [10000/50000 (20%)]\t Loss 254.503784\n",
      "Train Epoch: 22 [20000/50000 (40%)]\t Loss 261.283508\n",
      "Train Epoch: 22 [30000/50000 (60%)]\t Loss 326.811798\n",
      "Train Epoch: 22 [40000/50000 (80%)]\t Loss 345.214569\n",
      "Accuracy of model on test set 35.00\n",
      "Train Epoch: 23 [0/50000 (0%)]\t Loss 347.485413\n",
      "Train Epoch: 23 [10000/50000 (20%)]\t Loss 334.937653\n",
      "Train Epoch: 23 [20000/50000 (40%)]\t Loss 333.773438\n",
      "Train Epoch: 23 [30000/50000 (60%)]\t Loss 291.518005\n",
      "Train Epoch: 23 [40000/50000 (80%)]\t Loss 344.114319\n",
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 24 [0/50000 (0%)]\t Loss 307.637146\n",
      "Train Epoch: 24 [10000/50000 (20%)]\t Loss 309.525818\n",
      "Train Epoch: 24 [20000/50000 (40%)]\t Loss 299.131531\n",
      "Train Epoch: 24 [30000/50000 (60%)]\t Loss 329.297028\n",
      "Train Epoch: 24 [40000/50000 (80%)]\t Loss 357.320526\n",
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 25 [0/50000 (0%)]\t Loss 318.264801\n",
      "Train Epoch: 25 [10000/50000 (20%)]\t Loss 362.273102\n",
      "Train Epoch: 25 [20000/50000 (40%)]\t Loss 343.956085\n",
      "Train Epoch: 25 [30000/50000 (60%)]\t Loss 305.404938\n",
      "Train Epoch: 25 [40000/50000 (80%)]\t Loss 333.890472\n",
      "Accuracy of model on test set 35.00\n",
      "Train Epoch: 26 [0/50000 (0%)]\t Loss 334.747620\n",
      "Train Epoch: 26 [10000/50000 (20%)]\t Loss 322.359344\n",
      "Train Epoch: 26 [20000/50000 (40%)]\t Loss 345.312958\n",
      "Train Epoch: 26 [30000/50000 (60%)]\t Loss 324.137360\n",
      "Train Epoch: 26 [40000/50000 (80%)]\t Loss 335.960327\n",
      "Accuracy of model on test set 35.00\n",
      "Train Epoch: 27 [0/50000 (0%)]\t Loss 336.180450\n",
      "Train Epoch: 27 [10000/50000 (20%)]\t Loss 296.937866\n",
      "Train Epoch: 27 [20000/50000 (40%)]\t Loss 262.445923\n",
      "Train Epoch: 27 [30000/50000 (60%)]\t Loss 287.968781\n",
      "Train Epoch: 27 [40000/50000 (80%)]\t Loss 326.664062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 28 [0/50000 (0%)]\t Loss 274.751434\n",
      "Train Epoch: 28 [10000/50000 (20%)]\t Loss 333.888519\n",
      "Train Epoch: 28 [20000/50000 (40%)]\t Loss 304.672058\n",
      "Train Epoch: 28 [30000/50000 (60%)]\t Loss 322.105316\n",
      "Train Epoch: 28 [40000/50000 (80%)]\t Loss 317.140472\n",
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 29 [0/50000 (0%)]\t Loss 311.733398\n",
      "Train Epoch: 29 [10000/50000 (20%)]\t Loss 365.297394\n",
      "Train Epoch: 29 [20000/50000 (40%)]\t Loss 271.802612\n",
      "Train Epoch: 29 [30000/50000 (60%)]\t Loss 330.006104\n",
      "Train Epoch: 29 [40000/50000 (80%)]\t Loss 272.941010\n",
      "Accuracy of model on test set 36.00\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "n_hidden = [512, 256, 128]\n",
    "l2 = 0.0\n",
    "drop_p = 0.3\n",
    "loss_type = 'softmax'\n",
    "model = MLP(n_in, n_hidden, drop_p, n_out)\n",
    "modeleval = ModelEvaluator(model, epochs, lr, loss_type=loss_type, l2=l2, use_gpu=True)\n",
    "modeleval.evaluator(trainloader, testloader, print_every=100, validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIJRSSjmlCUIppZRTmiCUUko59f/T/aaZD82ORQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab9d3fd6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modeleval.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\t Loss 12674.858398\n",
      "Train Epoch: 0 [10000/50000 (20%)]\t Loss 6078.514648\n",
      "Train Epoch: 0 [20000/50000 (40%)]\t Loss 4886.843262\n",
      "Train Epoch: 0 [30000/50000 (60%)]\t Loss 4371.141113\n",
      "Train Epoch: 0 [40000/50000 (80%)]\t Loss 4731.263672\n",
      "Accuracy of model on test set 14.00\n",
      "Train Epoch: 1 [0/50000 (0%)]\t Loss 4765.041992\n",
      "Train Epoch: 1 [10000/50000 (20%)]\t Loss 4701.967773\n",
      "Train Epoch: 1 [20000/50000 (40%)]\t Loss 4686.915527\n",
      "Train Epoch: 1 [30000/50000 (60%)]\t Loss 4720.415527\n",
      "Train Epoch: 1 [40000/50000 (80%)]\t Loss 3927.243408\n",
      "Accuracy of model on test set 18.00\n",
      "Train Epoch: 2 [0/50000 (0%)]\t Loss 3992.971436\n",
      "Train Epoch: 2 [10000/50000 (20%)]\t Loss 4598.906250\n",
      "Train Epoch: 2 [20000/50000 (40%)]\t Loss 4329.773926\n",
      "Train Epoch: 2 [30000/50000 (60%)]\t Loss 3868.677734\n",
      "Train Epoch: 2 [40000/50000 (80%)]\t Loss 3981.881592\n",
      "Accuracy of model on test set 21.00\n",
      "Train Epoch: 3 [0/50000 (0%)]\t Loss 4665.524902\n",
      "Train Epoch: 3 [10000/50000 (20%)]\t Loss 4463.623535\n",
      "Train Epoch: 3 [20000/50000 (40%)]\t Loss 4664.423828\n",
      "Train Epoch: 3 [30000/50000 (60%)]\t Loss 3744.589844\n",
      "Train Epoch: 3 [40000/50000 (80%)]\t Loss 4530.812988\n",
      "Accuracy of model on test set 23.00\n",
      "Train Epoch: 4 [0/50000 (0%)]\t Loss 5197.607422\n",
      "Train Epoch: 4 [10000/50000 (20%)]\t Loss 3726.487793\n",
      "Train Epoch: 4 [20000/50000 (40%)]\t Loss 4108.868652\n",
      "Train Epoch: 4 [30000/50000 (60%)]\t Loss 4226.073730\n",
      "Train Epoch: 4 [40000/50000 (80%)]\t Loss 3503.584473\n",
      "Accuracy of model on test set 24.00\n",
      "Train Epoch: 5 [0/50000 (0%)]\t Loss 3328.414795\n",
      "Train Epoch: 5 [10000/50000 (20%)]\t Loss 3366.768555\n",
      "Train Epoch: 5 [20000/50000 (40%)]\t Loss 3823.426514\n",
      "Train Epoch: 5 [30000/50000 (60%)]\t Loss 4717.512207\n",
      "Train Epoch: 5 [40000/50000 (80%)]\t Loss 3813.685547\n",
      "Accuracy of model on test set 25.00\n",
      "Train Epoch: 6 [0/50000 (0%)]\t Loss 4688.311523\n",
      "Train Epoch: 6 [10000/50000 (20%)]\t Loss 4700.510254\n",
      "Train Epoch: 6 [20000/50000 (40%)]\t Loss 3803.868164\n",
      "Train Epoch: 6 [30000/50000 (60%)]\t Loss 4921.384766\n",
      "Train Epoch: 6 [40000/50000 (80%)]\t Loss 3573.333984\n",
      "Accuracy of model on test set 26.00\n",
      "Train Epoch: 7 [0/50000 (0%)]\t Loss 4382.546875\n",
      "Train Epoch: 7 [10000/50000 (20%)]\t Loss 5258.847168\n",
      "Train Epoch: 7 [20000/50000 (40%)]\t Loss 5053.264648\n",
      "Train Epoch: 7 [30000/50000 (60%)]\t Loss 4903.746094\n",
      "Train Epoch: 7 [40000/50000 (80%)]\t Loss 4481.254883\n",
      "Accuracy of model on test set 28.00\n",
      "Train Epoch: 8 [0/50000 (0%)]\t Loss 4721.197266\n",
      "Train Epoch: 8 [10000/50000 (20%)]\t Loss 4059.701660\n",
      "Train Epoch: 8 [20000/50000 (40%)]\t Loss 4193.201660\n",
      "Train Epoch: 8 [30000/50000 (60%)]\t Loss 4060.146240\n",
      "Train Epoch: 8 [40000/50000 (80%)]\t Loss 5288.622559\n",
      "Accuracy of model on test set 29.00\n",
      "Train Epoch: 9 [0/50000 (0%)]\t Loss 2922.249756\n",
      "Train Epoch: 9 [10000/50000 (20%)]\t Loss 5153.829102\n",
      "Train Epoch: 9 [20000/50000 (40%)]\t Loss 5473.985352\n",
      "Train Epoch: 9 [30000/50000 (60%)]\t Loss 4339.977539\n",
      "Train Epoch: 9 [40000/50000 (80%)]\t Loss 6015.051270\n",
      "Accuracy of model on test set 29.00\n",
      "Train Epoch: 10 [0/50000 (0%)]\t Loss 3859.164795\n",
      "Train Epoch: 10 [10000/50000 (20%)]\t Loss 4471.376953\n",
      "Train Epoch: 10 [20000/50000 (40%)]\t Loss 4677.044922\n",
      "Train Epoch: 10 [30000/50000 (60%)]\t Loss 4486.310547\n",
      "Train Epoch: 10 [40000/50000 (80%)]\t Loss 4170.102539\n",
      "Accuracy of model on test set 30.00\n",
      "Train Epoch: 11 [0/50000 (0%)]\t Loss 4868.274414\n",
      "Train Epoch: 11 [10000/50000 (20%)]\t Loss 5206.854492\n",
      "Train Epoch: 11 [20000/50000 (40%)]\t Loss 4063.583496\n",
      "Train Epoch: 11 [30000/50000 (60%)]\t Loss 4332.262207\n",
      "Train Epoch: 11 [40000/50000 (80%)]\t Loss 4610.377930\n",
      "Accuracy of model on test set 31.00\n",
      "Train Epoch: 12 [0/50000 (0%)]\t Loss 4554.806152\n",
      "Train Epoch: 12 [10000/50000 (20%)]\t Loss 4560.692871\n",
      "Train Epoch: 12 [20000/50000 (40%)]\t Loss 4396.313477\n",
      "Train Epoch: 12 [30000/50000 (60%)]\t Loss 3915.264160\n",
      "Train Epoch: 12 [40000/50000 (80%)]\t Loss 3473.181396\n",
      "Accuracy of model on test set 31.00\n",
      "Train Epoch: 13 [0/50000 (0%)]\t Loss 3756.039062\n",
      "Train Epoch: 13 [10000/50000 (20%)]\t Loss 4310.486816\n",
      "Train Epoch: 13 [20000/50000 (40%)]\t Loss 4309.060059\n",
      "Train Epoch: 13 [30000/50000 (60%)]\t Loss 3350.228271\n",
      "Train Epoch: 13 [40000/50000 (80%)]\t Loss 4296.741211\n",
      "Accuracy of model on test set 32.00\n",
      "Train Epoch: 14 [0/50000 (0%)]\t Loss 5472.847168\n",
      "Train Epoch: 14 [10000/50000 (20%)]\t Loss 5020.608398\n",
      "Train Epoch: 14 [20000/50000 (40%)]\t Loss 4267.236328\n",
      "Train Epoch: 14 [30000/50000 (60%)]\t Loss 4171.555664\n",
      "Train Epoch: 14 [40000/50000 (80%)]\t Loss 4932.690430\n",
      "Accuracy of model on test set 32.00\n",
      "Train Epoch: 15 [0/50000 (0%)]\t Loss 4524.868164\n",
      "Train Epoch: 15 [10000/50000 (20%)]\t Loss 4185.463379\n",
      "Train Epoch: 15 [20000/50000 (40%)]\t Loss 3599.897949\n",
      "Train Epoch: 15 [30000/50000 (60%)]\t Loss 4659.370117\n",
      "Train Epoch: 15 [40000/50000 (80%)]\t Loss 5178.046387\n",
      "Accuracy of model on test set 33.00\n",
      "Train Epoch: 16 [0/50000 (0%)]\t Loss 4736.773926\n",
      "Train Epoch: 16 [10000/50000 (20%)]\t Loss 4214.465332\n",
      "Train Epoch: 16 [20000/50000 (40%)]\t Loss 5762.150391\n",
      "Train Epoch: 16 [30000/50000 (60%)]\t Loss 4481.404297\n",
      "Train Epoch: 16 [40000/50000 (80%)]\t Loss 3731.532715\n",
      "Accuracy of model on test set 32.00\n",
      "Train Epoch: 17 [0/50000 (0%)]\t Loss 4001.498779\n",
      "Train Epoch: 17 [10000/50000 (20%)]\t Loss 5176.389648\n",
      "Train Epoch: 17 [20000/50000 (40%)]\t Loss 4447.869141\n",
      "Train Epoch: 17 [30000/50000 (60%)]\t Loss 4267.975586\n",
      "Train Epoch: 17 [40000/50000 (80%)]\t Loss 3600.699463\n",
      "Accuracy of model on test set 33.00\n",
      "Train Epoch: 18 [0/50000 (0%)]\t Loss 4501.737305\n",
      "Train Epoch: 18 [10000/50000 (20%)]\t Loss 4640.041992\n",
      "Train Epoch: 18 [20000/50000 (40%)]\t Loss 4288.286621\n",
      "Train Epoch: 18 [30000/50000 (60%)]\t Loss 4657.399414\n",
      "Train Epoch: 18 [40000/50000 (80%)]\t Loss 4165.454102\n",
      "Accuracy of model on test set 33.00\n",
      "Train Epoch: 19 [0/50000 (0%)]\t Loss 3518.888428\n",
      "Train Epoch: 19 [10000/50000 (20%)]\t Loss 4064.219482\n",
      "Train Epoch: 19 [20000/50000 (40%)]\t Loss 5215.768555\n",
      "Train Epoch: 19 [30000/50000 (60%)]\t Loss 3096.023193\n",
      "Train Epoch: 19 [40000/50000 (80%)]\t Loss 4507.800293\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 20 [0/50000 (0%)]\t Loss 4499.232422\n",
      "Train Epoch: 20 [10000/50000 (20%)]\t Loss 4686.125977\n",
      "Train Epoch: 20 [20000/50000 (40%)]\t Loss 5437.083496\n",
      "Train Epoch: 20 [30000/50000 (60%)]\t Loss 3064.620117\n",
      "Train Epoch: 20 [40000/50000 (80%)]\t Loss 3953.105469\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 21 [0/50000 (0%)]\t Loss 4282.899414\n",
      "Train Epoch: 21 [10000/50000 (20%)]\t Loss 3897.500977\n",
      "Train Epoch: 21 [20000/50000 (40%)]\t Loss 3590.186768\n",
      "Train Epoch: 21 [30000/50000 (60%)]\t Loss 5121.947266\n",
      "Train Epoch: 21 [40000/50000 (80%)]\t Loss 3890.349121\n",
      "Accuracy of model on test set 35.00\n",
      "Train Epoch: 22 [0/50000 (0%)]\t Loss 4776.700684\n",
      "Train Epoch: 22 [10000/50000 (20%)]\t Loss 4487.747070\n",
      "Train Epoch: 22 [20000/50000 (40%)]\t Loss 4636.530273\n",
      "Train Epoch: 22 [30000/50000 (60%)]\t Loss 4229.141602\n",
      "Train Epoch: 22 [40000/50000 (80%)]\t Loss 3966.349854\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 23 [0/50000 (0%)]\t Loss 4494.415039\n",
      "Train Epoch: 23 [10000/50000 (20%)]\t Loss 4264.801758\n",
      "Train Epoch: 23 [20000/50000 (40%)]\t Loss 4647.549805\n",
      "Train Epoch: 23 [30000/50000 (60%)]\t Loss 3796.774902\n",
      "Train Epoch: 23 [40000/50000 (80%)]\t Loss 4651.685059\n",
      "Accuracy of model on test set 35.00\n",
      "Train Epoch: 24 [0/50000 (0%)]\t Loss 5297.990234\n",
      "Train Epoch: 24 [10000/50000 (20%)]\t Loss 4913.095703\n",
      "Train Epoch: 24 [20000/50000 (40%)]\t Loss 4467.394531\n",
      "Train Epoch: 24 [30000/50000 (60%)]\t Loss 4092.695801\n",
      "Train Epoch: 24 [40000/50000 (80%)]\t Loss 3723.565186\n",
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 25 [0/50000 (0%)]\t Loss 4247.513184\n",
      "Train Epoch: 25 [10000/50000 (20%)]\t Loss 3669.246094\n",
      "Train Epoch: 25 [20000/50000 (40%)]\t Loss 5278.224609\n",
      "Train Epoch: 25 [30000/50000 (60%)]\t Loss 4500.902832\n",
      "Train Epoch: 25 [40000/50000 (80%)]\t Loss 4753.358398\n",
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 26 [0/50000 (0%)]\t Loss 3035.839844\n",
      "Train Epoch: 26 [10000/50000 (20%)]\t Loss 5037.188477\n",
      "Train Epoch: 26 [20000/50000 (40%)]\t Loss 4608.184570\n",
      "Train Epoch: 26 [30000/50000 (60%)]\t Loss 4084.247070\n",
      "Train Epoch: 26 [40000/50000 (80%)]\t Loss 4457.306641\n",
      "Accuracy of model on test set 34.00\n",
      "Train Epoch: 27 [0/50000 (0%)]\t Loss 5149.208496\n",
      "Train Epoch: 27 [10000/50000 (20%)]\t Loss 5743.835449\n",
      "Train Epoch: 27 [20000/50000 (40%)]\t Loss 5538.142090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [30000/50000 (60%)]\t Loss 3904.100098\n",
      "Train Epoch: 27 [40000/50000 (80%)]\t Loss 4538.813965\n",
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 28 [0/50000 (0%)]\t Loss 3021.942871\n",
      "Train Epoch: 28 [10000/50000 (20%)]\t Loss 5392.777832\n",
      "Train Epoch: 28 [20000/50000 (40%)]\t Loss 4385.253906\n",
      "Train Epoch: 28 [30000/50000 (60%)]\t Loss 4644.941895\n",
      "Train Epoch: 28 [40000/50000 (80%)]\t Loss 5089.250488\n",
      "Accuracy of model on test set 36.00\n",
      "Train Epoch: 29 [0/50000 (0%)]\t Loss 3947.464600\n",
      "Train Epoch: 29 [10000/50000 (20%)]\t Loss 3997.552979\n",
      "Train Epoch: 29 [20000/50000 (40%)]\t Loss 4638.043945\n",
      "Train Epoch: 29 [30000/50000 (60%)]\t Loss 4138.790527\n",
      "Train Epoch: 29 [40000/50000 (80%)]\t Loss 3981.148682\n",
      "Accuracy of model on test set 36.00\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "n_hidden = [512, 256, 128]\n",
    "l2 = 0.0\n",
    "drop_p = 0.3\n",
    "loss_type = 'hinge'\n",
    "model = MLP(n_in, n_hidden, drop_p, n_out)\n",
    "modeleval = ModelEvaluator(model, epochs, lr, loss_type=loss_type, l2=l2, use_gpu=True)\n",
    "modeleval.evaluator(trainloader, testloader, print_every=100, validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab80196978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modeleval.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0%)]\t Loss 483.434937\n",
      "Train Epoch: 0 [10000/50000 (20%)]\t Loss 343.070465\n",
      "Train Epoch: 0 [20000/50000 (40%)]\t Loss 343.476562\n",
      "Train Epoch: 0 [30000/50000 (60%)]\t Loss 346.431183\n",
      "Train Epoch: 0 [40000/50000 (80%)]\t Loss 340.990753\n",
      "Accuracy of model on test set 9.00\n",
      "Train Epoch: 1 [0/50000 (0%)]\t Loss 342.678925\n",
      "Train Epoch: 1 [10000/50000 (20%)]\t Loss 351.759521\n",
      "Train Epoch: 1 [20000/50000 (40%)]\t Loss 362.831024\n",
      "Train Epoch: 1 [30000/50000 (60%)]\t Loss 343.526123\n",
      "Train Epoch: 1 [40000/50000 (80%)]\t Loss 345.113922\n",
      "Accuracy of model on test set 9.00\n",
      "Train Epoch: 2 [0/50000 (0%)]\t Loss 347.456604\n",
      "Train Epoch: 2 [10000/50000 (20%)]\t Loss 339.988831\n",
      "Train Epoch: 2 [20000/50000 (40%)]\t Loss 359.540222\n",
      "Train Epoch: 2 [30000/50000 (60%)]\t Loss 348.270416\n",
      "Train Epoch: 2 [40000/50000 (80%)]\t Loss 354.577545\n",
      "Accuracy of model on test set 10.00\n",
      "Train Epoch: 3 [0/50000 (0%)]\t Loss 340.275330\n",
      "Train Epoch: 3 [10000/50000 (20%)]\t Loss 348.450897\n",
      "Train Epoch: 3 [20000/50000 (40%)]\t Loss 355.176483\n",
      "Train Epoch: 3 [30000/50000 (60%)]\t Loss 339.252502\n",
      "Train Epoch: 3 [40000/50000 (80%)]\t Loss 351.156372\n",
      "Accuracy of model on test set 9.00\n",
      "Train Epoch: 4 [0/50000 (0%)]\t Loss 351.523468\n",
      "Train Epoch: 4 [10000/50000 (20%)]\t Loss 338.755981\n",
      "Train Epoch: 4 [20000/50000 (40%)]\t Loss 349.283325\n",
      "Train Epoch: 4 [30000/50000 (60%)]\t Loss 352.522827\n",
      "Train Epoch: 4 [40000/50000 (80%)]\t Loss 336.976013\n",
      "Accuracy of model on test set 10.00\n",
      "Train Epoch: 5 [0/50000 (0%)]\t Loss 347.492371\n",
      "Train Epoch: 5 [10000/50000 (20%)]\t Loss 351.430634\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "n_hidden = [512, 256, 128]\n",
    "l2 = 0\n",
    "drop_p = 0.3\n",
    "loss_type_ = ['softmax', 'hinge']\n",
    "optim_ = ['sgd', 'rmsprop', 'adam', 'adagrad', 'adadelta']\n",
    "non_lin_ = ['tanh','relu', 'sigmoid']\n",
    "\n",
    "for l_t in loss_type_:\n",
    "    for opt in optim_:\n",
    "        for nlin in non_lin_:\n",
    "            model = MLP(n_in, n_hidden, drop_p, n_out, nlin)\n",
    "            modeleval = ModelEvaluator(model, epochs, lr, loss_type=l_t, l2=l2, use_gpu=True, optim=opt)\n",
    "            acc_ = modeleval.evaluator(trainloader, testloader, print_every=100, validation=False)\n",
    "            modelname = 'model_loss_{}_optimizer{}_nonlin_{}'.format(l_t, opt, nlin)\n",
    "            print('Accuracy of {0} is {1:.2f}'.format(modelname, acc_))\n",
    "            torch.save(modeleval.model.state_dict(), modelname)\n",
    "            plt = modeleval.plot_loss()\n",
    "            plt.savefig('train_test_loss_losstype: {0}, optim{1}, non_lin{2}'.format())\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
