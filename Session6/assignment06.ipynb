{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 6\n",
    "\n",
    "\n",
    "Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from model import Encoder, Decoder, LogisticRegression\n",
    "from evaluator import ModelEvaluator, AutoEncoderEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use latent features to train and test a simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_name, key='state_dict_encoder'):\n",
    "    model_dir = '../Session6/model/' + model_name\n",
    "    checkpoint = torch.load(model_dir)\n",
    "    checkpoint = checkpoint[key]\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 10\n",
    "lr = 0.001\n",
    "# Model\n",
    "l2 = 0.0\n",
    "optim = 'adam'\n",
    "encoder_epoch = 8\n",
    "use_gpu= True\n",
    "model_name = 'AutoEncoder_lr_{}_opt_{}_epoch_{}'.format(lr, optim, encoder_epoch)\n",
    "\n",
    "encoder = Encoder(batch_size=batch_size)\n",
    "decoder = Decoder(batch_size=batch_size)\n",
    "if use_gpu:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "encoder.load_state_dict(load_model(model_name, key='state_dict_encoder'))\n",
    "decoder.load_state_dict(load_model(model_name, key='state_dict_decoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset = dsets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "testset = dsets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=3)\n",
    "\n",
    "def plot_img(tensor, num_cols=10):\n",
    "  num_imgs = tensor.shape[0]\n",
    "  num_rows = 1+ num_imgs // num_cols\n",
    "  fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "  for i in range(num_imgs):\n",
    "    ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "    ax1.imshow(tensor[i])\n",
    "    ax1.axis('off')\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.set_yticklabels([])\n",
    "\n",
    "  plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "  plt.show() \n",
    "\n",
    "for images, labels in testloader:\n",
    "    output = encoder.forward(images.cuda())\n",
    "    output = decoder.forward(output)\n",
    "    break\n",
    "\n",
    "plot_img(images.detach().cpu().numpy())    \n",
    "'''\n",
    "img = images[0].cpu()\n",
    "print(img.shape)\n",
    "output_img = output[0].cpu()\n",
    "origin = img.data.numpy().transpose((1, 2, 0))\n",
    "out = output_img.data.numpy().transpose((1, 2, 0))\n",
    "\n",
    "plt.imshow(origin)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(out)\n",
    "plt.show()\n",
    "\n",
    "print(labels[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_in = 32768  # 512x8x8\n",
    "n_hidden = 128\n",
    "n_out = 10\n",
    "model_epochs = 20\n",
    "model_lr = 0.001\n",
    "l2 = 0.0\n",
    "#train classifier\n",
    "model = LogisticRegression(n_in, n_hidden, n_out)\n",
    "modeleval = ModelEvaluator(model, model_epochs, model_lr, l2=l2, use_gpu=True, optim='adam')\n",
    "acc_ = modeleval.evaluator(encoder, trainloader, testloader, noise=add_noise, print_every=100)\n",
    "'''\n",
    "for b_idx, (train_data, train_labels) in enumerate(trainloader):\n",
    "    if add_noise:\n",
    "            train_data_n = torch.mul(train_data+0.25, 0.1 * torch.rand(batch_size, 3, 32, 32))\n",
    "    if use_gpu:\n",
    "        train_data = train_data.cuda(non_blocking=True)\n",
    "        train_labels = train_labels.cuda()\n",
    "\n",
    "    if add_noise:\n",
    "        latent_repr = encoder.forward(train_data_n)\n",
    "    else:\n",
    "        latent_repr = encoder.forward(train_data)\n",
    "    print(latent_repr.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeleval.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising AutoEncoder\n",
    "\n",
    "Add noise to encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "lr = 0.001\n",
    "# Model\n",
    "l2 = 0.0\n",
    "optim = 'adam'\n",
    "model_name = 'AutoEncoder_lr_{}_opt_{}_epoch_{}'.format(lr, optim, encoder_epoch)\n",
    "model_name = model_name + '_dae'\n",
    "\n",
    "encoder = Encoder(batch_size=batch_size)\n",
    "encoder_epoch = 10\n",
    "encoder.load_state_dict(load_encoder(model_name))\n",
    "\n",
    "\n",
    "n_in = 32768  # 512x8x8\n",
    "n_hidden = 512\n",
    "n_out = 10\n",
    "model_epochs = 20\n",
    "model_lr = 0.001\n",
    "l2 = 0.0\n",
    "#train classifier\n",
    "model = LogisticRegression(n_in, n_hidden, n_out)\n",
    "modeleval = ModelEvaluator(model, model_epochs, model_lr, l2=l2, use_gpu=True, optim='adam')\n",
    "acc_ = modeleval.evaluator(encoder, trainloader, testloader, noise=add_noise, print_every=100)\n",
    "\n",
    "print('Accuracy on test set {.2f}'.format(acc_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get latent features from Soccer Dataset and train a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from test_soccer import run_trainer, test_img\n",
    "from soccer_dataset import SoccerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "encoder = Encoder(batch_size=batch_size)\n",
    "encoder_epoch = 10\n",
    "lr = 0.001\n",
    "optim = 'adam'\n",
    "model_name = 'AutoEncoder_lr_{}_opt_{}_epoch_{}'.format(lr, optim, encoder_epoch)\n",
    "encoder.load_state_dict(load_encoder(model_name))\n",
    "\n",
    "n_in = 32768  # 512x8x8\n",
    "n_hidden = 512\n",
    "n_out = 10\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "\n",
    "model = LogisticRegression(n_in, n_hidden, n_out)\n",
    "dataset = SoccerDataset(transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "run_trainer(dataloader, encoder, model, batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test classifier on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = 'Session6/SoccerData/test'\n",
    "img1_path = test_path + '/test1.jpg'\n",
    "test_img(img1_path, encoder, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
