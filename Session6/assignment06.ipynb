{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 6\n",
    "\n",
    "\n",
    "Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from model import Encoder, Decoder\n",
    "from evaluator import ModelEvaluator, AutoEncoderEvaluator\n",
    "from test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use latent features to train and test a simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_encoder(epoch=1, model_name):\n",
    "    model_dir = '../Session6/model/' + model_name\n",
    "    checkpoint = torch.load(model_dir)\n",
    "    checkpoint = checkpoint['state_dict_encoder']\n",
    "    return checkpoint\n",
    "\n",
    "def load_model(epoch=1, model_name):\n",
    "    model_dir = '../Session6/model/' + model_name\n",
    "    checkpoint = torch.load(model_dir)\n",
    "    checkpoint = checkpoint['state_dict']\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "lr = 0.001\n",
    "# Model\n",
    "l2 = 0.0\n",
    "optim = 'adam'\n",
    "model_name = 'AutoEncoder_lr_{}_opt_{}'.format(lr, optim)\n",
    "\n",
    "encoder = Encoder(batch_size=batch_size)\n",
    "encoder_epoch = 10\n",
    "encoder.load_state_dict(load_encoder(model_name, epoch=encoder_epoch))\n",
    "\n",
    "\n",
    "#\n",
    "n_in = 32768  # 512x8x8\n",
    "n_hidden = 512\n",
    "n_out = 10\n",
    "model_epochs = 20\n",
    "model_lr = 0.001\n",
    "l2 = 0.0\n",
    "#train classifier\n",
    "model = LogisticRegression(n_in, n_hidden, n_out)\n",
    "modeleval = ModelEvaluator(model, model_epochs, model_lr, l2=l2, use_gpu=True, optim='adam')\n",
    "acc_ = modeleval.evaluator(encoder, trainloader, testloader, noise=add_noise, print_every=100, validation=False)\n",
    "\n",
    "print('Accuracy on test set {.2f}'.format(acc_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeleval.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising AutoEncoder\n",
    "\n",
    "Add noise to encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "lr = 0.001\n",
    "# Model\n",
    "l2 = 0.0\n",
    "optim = 'adam'\n",
    "model_name = 'AutoEncoder_lr_{}_opt_{}'.format(lr, optim)\n",
    "model_name = model_name + '_dae'\n",
    "\n",
    "encoder = Encoder(batch_size=batch_size)\n",
    "encoder_epoch = 10\n",
    "encoder.load_state_dict(load_encoder(model_name, epoch=encoder_epoch))\n",
    "\n",
    "\n",
    "n_in = 32768  # 512x8x8\n",
    "n_hidden = 512\n",
    "n_out = 10\n",
    "model_epochs = 20\n",
    "model_lr = 0.001\n",
    "l2 = 0.0\n",
    "#train classifier\n",
    "model = LogisticRegression(n_in, n_hidden, n_out)\n",
    "modeleval = ModelEvaluator(model, model_epochs, model_lr, l2=l2, use_gpu=True, optim='adam')\n",
    "acc_ = modeleval.evaluator(encoder, trainloader, testloader, noise=add_noise, print_every=100, validation=False)\n",
    "\n",
    "print('Accuracy on test set {.2f}'.format(acc_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get latent features from Soccer Dataset and train a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from test_soccer import run_trainer, test_img\n",
    "from soccer_dataset import SoccerDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "encoder = Encoder(batch_size=batch_size)\n",
    "encoder_epoch = 10\n",
    "lr = 0.001\n",
    "# Model\n",
    "l2 = 0.0\n",
    "optim = 'adam'\n",
    "model_name = 'AutoEncoder_lr_{}_opt_{}'.format(lr, optim)\n",
    "encoder.load_state_dict(load_encoder(model_name, epoch=encoder_epoch))\n",
    "\n",
    "n_in = 32768  # 512x8x8\n",
    "n_hidden = 512\n",
    "n_out = 10\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "\n",
    "model = LogisticRegression(n_in, n_hidden, n_out)\n",
    "dataset = SoccerDataset(transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "run_trainer(dataloader, encoder, model, batch_size, epochs, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test classifier on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = 'Session6/SoccerData/test'\n",
    "img1_path = test_path + '/test1.jpg'\n",
    "test_img(img1_path, encoder, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
